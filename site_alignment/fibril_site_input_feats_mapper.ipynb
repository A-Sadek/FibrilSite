{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74d53a48-4a1f-45fb-a64c-2cc30e390b47",
   "metadata": {
    "tags": []
   },
   "source": [
    "# This notebook is to map the isolated pocket points to input features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b763a8ef-31ba-489d-ad56-e2e3298f2aad",
   "metadata": {},
   "source": [
    "## 1.0 Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd93baf0-46ad-4f98-a7af-a63cbf991133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e38daf-df28-4e5d-b157-d254352986a9",
   "metadata": {},
   "source": [
    "## 2.0 Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50257ad3-c951-4e9f-9c03-f297952568d3",
   "metadata": {},
   "source": [
    "## 3.0 I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa91aba-e843-4795-8a9a-f731a3ed9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output dir\n",
    "output = os.path.join(os.path.abspath(\".\"), str(datetime.date.today())+\"_sites_parsed_info/\")\n",
    "os.makedirs(output, exist_ok=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e55aee-1cdc-4525-ac73-b75e3ecb9a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "# paths to the input feats folder\n",
    "input_feats_src   = os.path.abspath(\"../data_preparation/04b-precomputation_12A/precomputation/\")\n",
    "input_feats_paths = [f.strip() for f in glob.iglob(os.path.join(input_feats_src, \"*\", \"*\"))]\n",
    "print(len(input_feats_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd57c80c-9d4b-438b-b639-9eec4245cce1",
   "metadata": {},
   "source": [
    "## 4.0 Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f002d570-fe71-4248-afb7-448252239e74",
   "metadata": {},
   "source": [
    "### 4.1 Parse the isolated pocket points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8964f56-fe29-41b3-b2f2-a21e7f8ac9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408f55c36b814d73a5075fc59880884b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing defined sites:   0%|          | 0/599 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse the isolated pockets\n",
    "\n",
    "# container for storing the parsed sites\n",
    "vessel01 = [] \n",
    "\n",
    "for pocket in tqdm(sorted(glob.iglob(os.path.join(os.path.abspath(\"../sel_fibril_sites\"), \"*\", \"*.csv\"))), desc='parsing defined sites'):\n",
    "    if 'refined' in pocket or 'isolate' in pocket:\n",
    "        df_temp01 = pd.read_csv(pocket, index_col=0)\n",
    "        df_temp01.insert(0, 'fibril', os.path.basename(pocket).replace('.csv','').split('_')[1])\n",
    "        df_temp01.insert(1, 'pocket_id', \"_\".join(os.path.basename(pocket).replace('.csv','').split('_')[2:-1]))\n",
    "        df_temp01.insert(2, 'isolation', os.path.basename(pocket).replace('.csv','').split('_')[-1])\n",
    "        vessel01.append(df_temp01)\n",
    "\n",
    "# add all these parsed pockets to a dataframe\n",
    "df_pockets_crude = pd.concat(vessel01).reset_index(drop=1)\n",
    "\n",
    "print(len(set(df_pockets_crude.pocket_id)))\n",
    "print(df_pockets_crude.shape)\n",
    "df_pockets_crude.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9936df-99ec-4081-a451-4a34b159fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the isolate points for the pockets that underwent a round of refinement \n",
    "\n",
    "# container to contain the filtered points info\n",
    "vessel02 = [] \n",
    "\n",
    "for g01 in tqdm(df_pockets_crude.groupby(by='pocket_id'), desc='cleaning'):\n",
    "    if len(set(g01[1].isolation)) < 2 :\n",
    "        vessel02.append(g01[1])\n",
    "    else:\n",
    "        vessel02.append(g01[1][g01[1].isolation == 'refined'])\n",
    "\n",
    "df_pockets = pd.concat(vessel02).reset_index(drop=1)\n",
    "df_pockets.to_csv(os.path.join(output, str(datetime.date.today())+\"_all_sites_parsed.csv\"))\n",
    "\n",
    "print(len(set(df_pockets.pocket_id)))\n",
    "print(df_pockets.shape)\n",
    "df_pockets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ace6a6-1f60-4648-9661-897e2cd677ed",
   "metadata": {},
   "source": [
    "### 4.2 Get the computed surface features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae752a4a-8ced-4f88-a73d-b26aa27e1550",
   "metadata": {},
   "source": [
    "*surface feature parsing* \n",
    "\n",
    "MaSIF files are organzed in the manner of MaSIF point index that is the center of the patch, the 200 points within the patch and their computed surface features. We map the defined site points to their corresponding features based on the MaSIF indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ad76c-bd27-4cca-8d78-83b333c499ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# container for the full info\n",
    "vessel03 = [] \n",
    "\n",
    "for g02 in tqdm(df_pockets.groupby(by='fibril'), desc='getting feats'):\n",
    " \n",
    "    # load the input feat files\n",
    "    input_feats = np.load([f for f in input_feats_paths if g02[0] in f if os.path.basename(f) == \"p1_input_feat.npy\"][0])[:,0,:]\n",
    "    \n",
    "    # add the values\n",
    "    df_temp02 = g02[1]\n",
    "    df_temp02.insert(df_temp02.shape[1], 'input_si',     [input_feats[x][0] for x in df_temp02.MaSIF_index])\n",
    "    df_temp02.insert(df_temp02.shape[1], 'input_charge', [input_feats[x][3] for x in df_temp02.MaSIF_index])\n",
    "    df_temp02.insert(df_temp02.shape[1], 'input_hphob',  [input_feats[x][4] for x in df_temp02.MaSIF_index])\n",
    "    df_temp02.insert(df_temp02.shape[1], 'input_hbonds', [input_feats[x][2] for x in df_temp02.MaSIF_index])\n",
    "    \n",
    "    vessel03.append(df_temp02)\n",
    "    \n",
    "\n",
    "df_all_feats = pd.concat(vessel03).reset_index(drop=1)\n",
    "df_all_feats.to_csv(os.path.join(output, str(datetime.date.today())+\"_all_sites_input_feats.csv\"))\n",
    "\n",
    "print(df_all_feats.shape)\n",
    "df_all_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff51b42-ac15-4ba7-af26-a82cbe27afde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masif",
   "language": "python",
   "name": "masif"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
